{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tfx"
      ],
      "metadata": {
        "id": "mYqHi6nSU-Dc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qDh6dasU65p"
      },
      "source": [
        "### IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uNsem46tU65q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
        "from modules.pipeline import init_local_pipeline\n",
        "from modules.components import init_components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPwTNsdJU65r"
      },
      "source": [
        "### SET VARIABEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8DJgv4-ZU65r"
      },
      "outputs": [],
      "source": [
        "PIPELINE_NAME = 'diabetes-pipeline'\n",
        "\n",
        "DATA_ROOT = 'data'\n",
        "TRANSFORM_MODULE_FILE = 'modules/transform.py'\n",
        "TRAINER_MODULE_FILE = 'modules/trainer.py'\n",
        "\n",
        "OUTPUT_BASE = 'output'\n",
        "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
        "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
        "metadata_path = os.path.join(pipeline_root, 'metadata.sqlite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hFlLx8KU65r"
      },
      "source": [
        "### RUN PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3mZfyF8LU65r",
        "outputId": "de93963a-0636-48b1-8feb-7ac800350d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'tfx.orchestration.beam.beam_dag_runner.PipelineNodeAsDoFn'>)\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
            "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
            "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
            "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.transforms.combiners._TopPerBundle'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.transforms.combiners._TopPerBundle'>)\n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969350   nanos: 171865940 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969350   nanos: 178370714 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969350   nanos: 251731634 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969350   nanos: 258882045 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969360   nanos: 7123470 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_93\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969360   nanos: 56023836 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_94\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-10\" \n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " gender_xf (InputLayer)      [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " smoking_history_xf (InputL  [(None, 4)]                  0         []                            \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " age_xf (InputLayer)         [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " hypertension_xf (InputLaye  [(None, 1)]                  0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " heart_disease_xf (InputLay  [(None, 1)]                  0         []                            \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " bmi_xf (InputLayer)         [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " HbA1c_level_xf (InputLayer  [(None, 1)]                  0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " blood_glucose_level_xf (In  [(None, 1)]                  0         []                            \n",
            " putLayer)                                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 13)                   0         ['gender_xf[0][0]',           \n",
            "                                                                     'smoking_history_xf[0][0]',  \n",
            "                                                                     'age_xf[0][0]',              \n",
            "                                                                     'hypertension_xf[0][0]',     \n",
            "                                                                     'heart_disease_xf[0][0]',    \n",
            "                                                                     'bmi_xf[0][0]',              \n",
            "                                                                     'HbA1c_level_xf[0][0]',      \n",
            "                                                                     'blood_glucose_level_xf[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  3584      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   16448     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 16)                   1040      ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    17        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21089 (82.38 KB)\n",
            "Trainable params: 21089 (82.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 39s 7ms/step - loss: 0.1175 - binary_accuracy: 0.9598 - val_loss: 0.0996 - val_binary_accuracy: 0.9663\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0917 - binary_accuracy: 0.9688 - val_loss: 0.0866 - val_binary_accuracy: 0.9699\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0864 - binary_accuracy: 0.9698 - val_loss: 0.0976 - val_binary_accuracy: 0.9634\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0850 - binary_accuracy: 0.9703 - val_loss: 0.0837 - val_binary_accuracy: 0.9715\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0838 - binary_accuracy: 0.9708 - val_loss: 0.0840 - val_binary_accuracy: 0.9715\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0836 - binary_accuracy: 0.9708 - val_loss: 0.0879 - val_binary_accuracy: 0.9712\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0827 - binary_accuracy: 0.9712 - val_loss: 0.0897 - val_binary_accuracy: 0.9674\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0825 - binary_accuracy: 0.9713 - val_loss: 0.0834 - val_binary_accuracy: 0.9714\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0834 - binary_accuracy: 0.9708 - val_loss: 0.0830 - val_binary_accuracy: 0.9710\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0818 - binary_accuracy: 0.9716 - val_loss: 0.0830 - val_binary_accuracy: 0.9710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969787   nanos: 105689525 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969787   nanos: 112745046 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969787   nanos: 106102705 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/runners/worker/sdk_worker_main.py:361\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969787   nanos: 113432168 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/options/pipeline_options.py:394\" thread: \"MainThread\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969797   nanos: 521451234 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_335\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-12\" \n",
            "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1731969797   nanos: 534716367 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_334\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"/usr/local/lib/python3.10/dist-packages/apache_beam/io/tfrecordio.py:59\" thread: \"Thread-11\" \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:112: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
            "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
          ]
        }
      ],
      "source": [
        "components = init_components(\n",
        "    data_dir=DATA_ROOT,\n",
        "    transform_module=TRANSFORM_MODULE_FILE,\n",
        "    training_module=TRAINER_MODULE_FILE,\n",
        "    training_steps=5000,\n",
        "    eval_steps=1000,\n",
        "    serving_model_dir=serving_model_dir\n",
        ")\n",
        "\n",
        "pipeline = init_local_pipeline(components, pipeline_root)\n",
        "BeamDagRunner().run(pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VXdaqNeZU65s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34a79d1-054c-43a6-9b60-87bbd8f3fc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder '/content/output' berhasil di-zip menjadi '/content/output.zip'\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Daftar folder yang ingin di-zip\n",
        "folders_to_zip = ['/content/output']\n",
        "\n",
        "# Loop untuk men-zip setiap folder\n",
        "for folder in folders_to_zip:\n",
        "    zip_file_name = f\"{folder}.zip\"  # Nama file zip untuk setiap folder\n",
        "    shutil.make_archive(zip_file_name.replace('.zip', ''), 'zip', folder)\n",
        "    print(f\"Folder '{folder}' berhasil di-zip menjadi '{zip_file_name}'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "YypaEN-dZSLn"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}